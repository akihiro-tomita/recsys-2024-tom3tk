{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Iterable\n",
    "import zipfile\n",
    "\n",
    "#Logging\n",
    "import logging\n",
    "\n",
    "# ロガーの取得\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "file_handler = logging.FileHandler('logs.log')\n",
    "\n",
    "# # ログのフォーマットを設定\n",
    "formatter = logging.Formatter('[%(asctime)s][%(levelname)s] %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Notebook上にもログを表示するためのハンドラ\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = Path('/home/data/ebnerd_testset')\n",
    "\n",
    "test_behaviors = pl.read_parquet(TEST_DIR/'test'/'behaviors.parquet')\n",
    "test_history = pl.read_parquet(TEST_DIR/'test'/'history_extended.parquet')\n",
    "\n",
    "articles = pl.read_parquet('/home/data/ebnerd_testset/articles.parquet')\n",
    "\n",
    "#impression_idとuser_idでユニークかどうか\n",
    "assert len(test_behaviors) == len(test_behaviors.groupby(['impression_id','user_id']).count())\n",
    "\n",
    "sub_impression = test_behaviors.select(['impression_id','user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"./test_predictions/sub_df_orgs/\"\n",
    "\n",
    "chunks = []\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    path = os.path.join(BASE_DIR, [p for p in os.listdir(BASE_DIR) if f\"sub_df_org_chunk{i}.parquet\" in p][0])\n",
    "    print(path)\n",
    "    chunks.append(pl.read_parquet(path))\n",
    "\n",
    "sub_df = pl.concat(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = sub_df.with_columns([\n",
    "        pl.col('y_pred1').rank().over('impression_id').alias('y_pred1'),\n",
    "        pl.col('y_pred2').rank().over('impression_id').alias('y_pred2'),\n",
    "        pl.col('y_pred3').rank().over('impression_id').alias('y_pred3'),\n",
    "        pl.col('y_pred4').rank().over('impression_id').alias('y_pred4'),\n",
    "        pl.col('y_pred5').rank().over('impression_id').alias('y_pred5'),\n",
    "        pl.col('y_pred6').rank().over('impression_id').alias('y_pred6'),\n",
    "        pl.col('y_pred7').rank().over('impression_id').alias('y_pred7'),\n",
    "        pl.col('y_pred8').rank().over('impression_id').alias('y_pred8'),\n",
    "]).with_columns([\n",
    "    (\n",
    "                pl.col('y_pred1')*0.125 + \\\n",
    "                pl.col('y_pred2')*0.125 + \\\n",
    "                pl.col('y_pred3')*0.125 + \\\n",
    "                pl.col('y_pred4')*0.125 + \\\n",
    "                pl.col('y_pred5')*0.125 + \\\n",
    "                pl.col('y_pred6')*0.125 + \\\n",
    "                pl.col('y_pred7')*0.125 + \\\n",
    "                pl.col('y_pred8')*0.125\n",
    "    ).alias('pred')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impression_idごとにpredの順位をつける\n",
    "sub_df = sub_df.groupby(['impression_id','user_id']).agg(\n",
    "    pl.col('pred').rank(method = 'ordinal',descending = True).alias('prediction_scores')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parquetで保存\n",
    "sub_df.write_parquet('sub.parquet')\n",
    "\n",
    "#sub_impressionと同じ並びにする\n",
    "all_sub_df = sub_impression.join(sub_df, on=['impression_id','user_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission_file(\n",
    "    impression_ids: Iterable[int],\n",
    "    prediction_scores: Iterable[any],\n",
    "    path: Path = Path(\"predictions.txt\"),\n",
    "    rm_file: bool = True,\n",
    "    filename_zip: str = None,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    We align the submission file similar to MIND-format for users who are familar.\n",
    "\n",
    "    Reference:\n",
    "        https://github.com/recommenders-team/recommenders/blob/main/examples/00_quick_start/nrms_MIND.ipynb\n",
    "\n",
    "    Example:\n",
    "    >>> impression_ids = [237, 291, 320]\n",
    "    >>> prediction_scores = [[0.2, 0.1, 0.3], [0.1, 0.2], [0.4, 0.2, 0.1, 0.3]]\n",
    "    >>> write_submission_file(impression_ids, prediction_scores, path=\"predictions.txt\", rm_file=False)\n",
    "    ## Output file:\n",
    "        237 [0.2,0.1,0.3]\n",
    "        291 [0.1,0.2]\n",
    "        320 [0.4,0.2,0.1,0.3]\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    with open(path, \"w\") as f:\n",
    "        for impr_index, preds in tqdm(zip(impression_ids, prediction_scores)):\n",
    "            preds = \"[\" + \",\".join([str(i) for i in preds]) + \"]\"\n",
    "            f.write(\" \".join([str(impr_index), preds]) + \"\\n\")\n",
    "            \n",
    "    # =>\n",
    "    \n",
    "    zip_submission_file(path=path, rm_file=rm_file, filename_zip=filename_zip)\n",
    "\n",
    "\n",
    "def zip_submission_file(\n",
    "    path: Path,\n",
    "    filename_zip: str = None,\n",
    "    verbose: bool = True,\n",
    "    rm_file: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Compresses a specified file into a ZIP archive within the same directory.\n",
    "\n",
    "    Args:\n",
    "        path (Path): The directory path where the file to be zipped and the resulting zip file will be located.\n",
    "        filename_input (str, optional): The name of the file to be compressed. Defaults to the path.name.\n",
    "        filename_zip (str, optional): The name of the output ZIP file. Defaults to \"prediction.zip\".\n",
    "        verbose (bool, optional): If set to True, the function will print the process details. Defaults to True.\n",
    "        rm_file (bool, optional): If set to True, the original file will be removed after compression. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        None: This function does not return any value.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    if filename_zip:\n",
    "        path_zip = path.parent.joinpath(filename_zip)\n",
    "    else:\n",
    "        path_zip = path.with_suffix(\".zip\")\n",
    "\n",
    "    if path_zip.suffix != \".zip\":\n",
    "        raise ValueError(f\"suffix for {path_zip.name} has to be '.zip'\")\n",
    "    if verbose:\n",
    "        print(f\"Zipping {path} to {path_zip}\")\n",
    "    f = zipfile.ZipFile(path_zip, \"w\", zipfile.ZIP_DEFLATED)\n",
    "    f.write(path, arcname=path.name)\n",
    "    f.close()\n",
    "    if rm_file:\n",
    "        path.unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_impression_id = all_sub_df['impression_id'].to_list()\n",
    "sub_prediction_scores = all_sub_df['prediction_scores'].to_list()\n",
    "write_submission_file(\n",
    "    impression_ids=sub_impression_id,\n",
    "    prediction_scores=sub_prediction_scores,\n",
    "    path=\"predictions.txt\",\n",
    "    filename_zip=\"./test_predictions_final2/predictions.zip\",\n",
    ")\n",
    "\n",
    "logger.info('finish')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
