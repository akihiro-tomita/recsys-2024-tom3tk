{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Logging\n",
    "import logging\n",
    "\n",
    "# Get logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "file_handler = logging.FileHandler('logs.log')\n",
    "\n",
    "# Set log format\n",
    "formatter = logging.Formatter('[%(asctime)s][%(levelname)s] %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Settings to display log on notebook\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference & Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = pl.read_parquet('/home/data/ebnerd_testset/articles.parquet')\n",
    "\n",
    "lgb_model_part1 = lgb.Booster(model_file='lgb_model_20p_1.txt')\n",
    "lgb_model_part2 = lgb.Booster(model_file='lgb_model_20p_2.txt')\n",
    "lgb_model_part3 = lgb.Booster(model_file='lgb_model_20p_3.txt')\n",
    "lgb_model_part4 = lgb.Booster(model_file='lgb_model_20p_4.txt')\n",
    "lgb_model_part5 = lgb.Booster(model_file='lgb_model_20p_5.txt')\n",
    "lgb_model_part6 = lgb.Booster(model_file='lgb_model_20p_6.txt')\n",
    "lgb_model_part7 = lgb.Booster(model_file='lgb_model_20p_7.txt')\n",
    "lgb_model_part8 = lgb.Booster(model_file='lgb_model_20p_8.txt')\n",
    "\n",
    "feature_cols = lgb_model_part1.feature_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../test_predictions/\", exist_ok=True)\n",
    "os.makedirs(\"../test_predictions/sub_df_orgs/\", exist_ok=True)\n",
    "os.makedirs(\"../test_predictions/sub_dfs/\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sub_df_list = []\n",
    "sub_df_list_org = []\n",
    "\n",
    "for i in range(100):\n",
    "    logger.info(f'no : {i}')\n",
    "    \n",
    "    if f\"sub_df_org_chunk{i}.parquet\" in os.listdir(\"../test_predictions/sub_df_orgs/\"):\n",
    "        continue\n",
    "    \n",
    "    pl.DataFrame().write_parquet(f\"../test_predictions/sub_df_orgs/sub_df_org_chunk{i}.parquet\")\n",
    "    \n",
    "    pl.DataFrame()\n",
    "    \n",
    "    test_df = pl.read_parquet(f\"../test_large_chunks/test_df_chunk{i}.parquet\")\n",
    "    test_df = test_df.join(articles.select([\"article_id\", \"category\"]), how=\"left\", on=\"article_id\")\n",
    "    X_test = test_df.select(feature_cols).to_pandas()\n",
    "    \n",
    "    X_test[\"category\"] = X_test[\"category\"].astype(\"category\")\n",
    "    \n",
    "    logger.info(f'starting prediction')\n",
    "    lgb_pred_part1 = lgb_model_part1.predict(X_test)\n",
    "    lgb_pred_part2 = lgb_model_part2.predict(X_test)\n",
    "    lgb_pred_part3 = lgb_model_part3.predict(X_test)\n",
    "    lgb_pred_part4 = lgb_model_part4.predict(X_test)\n",
    "    lgb_pred_part5 = lgb_model_part5.predict(X_test)\n",
    "    lgb_pred_part6 = lgb_model_part6.predict(X_test)\n",
    "    lgb_pred_part7 = lgb_model_part7.predict(X_test)\n",
    "    lgb_pred_part8 = lgb_model_part8.predict(X_test)\n",
    "    \n",
    "    logger.info(f'organizing results')\n",
    "    sub_df_org = pl.DataFrame(\n",
    "        {\n",
    "            'impression_id': test_df['impression_id'],\n",
    "            'article_id': test_df['article_id'],\n",
    "            'user_id': test_df['user_id'],\n",
    "            'y_pred1': lgb_pred_part1,\n",
    "            'y_pred2': lgb_pred_part2,\n",
    "            'y_pred3': lgb_pred_part3,\n",
    "            'y_pred4': lgb_pred_part4,\n",
    "            'y_pred5': lgb_pred_part5,\n",
    "            'y_pred6': lgb_pred_part6,\n",
    "            'y_pred7': lgb_pred_part7,\n",
    "            'y_pred8': lgb_pred_part8,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Ensembles scores based on ranking of 8 models.\n",
    "    sub_df = sub_df_org.with_columns([\n",
    "            pl.col('y_pred1').rank().over('impression_id').alias('y_pred1'),\n",
    "            pl.col('y_pred2').rank().over('impression_id').alias('y_pred2'),\n",
    "            pl.col('y_pred3').rank().over('impression_id').alias('y_pred3'),\n",
    "            pl.col('y_pred4').rank().over('impression_id').alias('y_pred4'),\n",
    "            pl.col('y_pred5').rank().over('impression_id').alias('y_pred5'),\n",
    "            pl.col('y_pred6').rank().over('impression_id').alias('y_pred6'),\n",
    "            pl.col('y_pred7').rank().over('impression_id').alias('y_pred7'),\n",
    "            pl.col('y_pred8').rank().over('impression_id').alias('y_pred8'),\n",
    "    ]).with_columns([\n",
    "        (\n",
    "                    pl.col('y_pred1')*0.125 + \\\n",
    "                    pl.col('y_pred2')*0.125 + \\\n",
    "                    pl.col('y_pred3')*0.125 + \\\n",
    "                    pl.col('y_pred4')*0.125 + \\\n",
    "                    pl.col('y_pred5')*0.125 + \\\n",
    "                    pl.col('y_pred6')*0.125 + \\\n",
    "                    pl.col('y_pred7')*0.125 + \\\n",
    "                    pl.col('y_pred8')*0.125\n",
    "        ).alias('pred')\n",
    "    ])\n",
    "    \n",
    "    # Ranks prediction based on ensemble scores\n",
    "    sub_df = sub_df.groupby(['impression_id','user_id']).agg(\n",
    "        pl.col('pred').rank(method = 'ordinal',descending = True).alias('prediction_scores')\n",
    "    )\n",
    "    \n",
    "    sub_df_list.append(sub_df)\n",
    "    sub_df_list_org.append(sub_df_org)\n",
    "    \n",
    "    os.remove(f\"../test_predictions/sub_df_orgs/sub_df_org_chunk{i}.parquet\")\n",
    "    \n",
    "    sub_df_org.write_parquet(f\"../test_predictions/sub_df_orgs/sub_df_org_chunk{i}.parquet\")\n",
    "    sub_df.write_parquet(f\"../test_predictions/sub_dfs/sub_df_chunk{i}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
