{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os,sys,gc\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from glob import glob\n",
    "import pickle\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Logging\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "file_handler = logging.FileHandler('logs.log')\n",
    "\n",
    "formatter = logging.Formatter('[%(asctime)s][%(levelname)s] %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "stream_handler = logging.StreamHandler()\n",
    "stream_handler.setFormatter(formatter)\n",
    "logger.addHandler(stream_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Historyからitem2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PATH\n",
    "TRAIN_DIR = Path('/home/data/train_large')\n",
    "TEST_DIR = Path('/home/data/ebnerd_testset')\n",
    "\n",
    "trn_history = pl.read_parquet(TRAIN_DIR/'train'/'history.parquet')\n",
    "val_history = pl.read_parquet(TRAIN_DIR/'validation'/'history.parquet')\n",
    "test_history = pl.read_parquet(TEST_DIR/'test'/'history.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_history = trn_history['article_id_fixed'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_item2vec(item_history,vector_size):\n",
    "    model = Word2Vec(sentences=item_history, \n",
    "                 vector_size=vector_size, \n",
    "                 window=5, \n",
    "                 min_count=1,\n",
    "                 sg=0,\n",
    "                 hs=0,\n",
    "                 epochs=10,\n",
    "                 workers=12)\n",
    "    \n",
    "    item_emb_matrix = np.zeros((len(model.wv.index_to_key), vector_size))\n",
    "    for i, item in enumerate(model.wv.index_to_key):\n",
    "        item_emb_matrix[i] = model.wv[item]\n",
    "\n",
    "    vec_df = pl.from_numpy(item_emb_matrix).to_pandas()\n",
    "\n",
    "    #col名をvector_0, vector_1, ...に変更\n",
    "    vec_df.columns = ['vector_'+str(i) for i in range(vector_size)]    \n",
    "    vec_df['article_id'] = model.wv.index_to_key\n",
    "\n",
    "    #article_idをi32に変換\n",
    "    vec_df['article_id'] = vec_df['article_id'].astype('int32')\n",
    "\n",
    "    #vectorで始まるカラムをfloat32に変換\n",
    "    for col in vec_df.columns:\n",
    "        if 'vector' in col:\n",
    "            vec_df[col] = vec_df[col].astype('float32')\n",
    "\n",
    "    return vec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-12 08:46:33,678][INFO] Creating item2vec_1 for trn\n",
      "[2024-04-12 08:58:42,366][INFO] shape of vec_df: (69140, 65)\n",
      "[2024-04-12 08:58:42,848][INFO] Creating item2vec_1 for val\n",
      "[2024-04-12 09:09:50,585][INFO] shape of vec_df: (67719, 65)\n",
      "[2024-04-12 09:09:50,887][INFO] Creating item2vec_1 for test\n",
      "[2024-04-12 09:21:19,908][INFO] shape of vec_df: (68497, 65)\n"
     ]
    }
   ],
   "source": [
    "#item2vec_1\n",
    "\n",
    "#trn\n",
    "logger.info('Creating item2vec_1 for trn')\n",
    "\n",
    "vec_df = create_item2vec(trn_history['article_id_fixed'].to_list(),64)\n",
    "\n",
    "logger.info(f'shape of vec_df: {vec_df.shape}')\n",
    "\n",
    "#save as parquet\n",
    "vec_df.to_parquet('/home/data/item2vec_1/train_item2vec.parquet')\n",
    "\n",
    "#val\n",
    "logger.info('Creating item2vec_1 for val')\n",
    "vec_df = create_item2vec(val_history['article_id_fixed'].to_list(),64)\n",
    "\n",
    "logger.info(f'shape of vec_df: {vec_df.shape}')\n",
    "\n",
    "#save as parquet\n",
    "vec_df.to_parquet('/home/data/item2vec_1/valid_item2vec.parquet')\n",
    "\n",
    "#test\n",
    "logger.info('Creating item2vec_1 for test')\n",
    "vec_df = create_item2vec(test_history['article_id_fixed'].to_list(),64)\n",
    "\n",
    "logger.info(f'shape of vec_df: {vec_df.shape}')\n",
    "\n",
    "#save as parquet\n",
    "vec_df.to_parquet('/home/data/item2vec_1/test_item2vec.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
